{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import bs4 as bs\n",
    "import pickle\n",
    "import requests\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import pandas_datareader as pdr\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "style.use('ggplot')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, neighbors\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text.replace('\\n','')\n",
    "        if \".\" in ticker:\n",
    "            ticker = ticker.replace('.','-')\n",
    "            print('ticker replaced to', ticker) \n",
    "        tickers.append(ticker)\n",
    "        \n",
    "    with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
    "        pickle.dump(tickers,f)\n",
    "        \n",
    "    return tickers\n",
    "\n",
    "#save_sp500_tickers()\n",
    "\n",
    "def get_data_from_yahoo(reload_sp500=False):\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "\n",
    "    start = dt.datetime(2010, 1, 1)\n",
    "    end = dt.datetime.now()\n",
    "    for ticker in tickers:\n",
    "        \n",
    "        # just in case your connection breaks, we'd like to save our progress!\n",
    "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "            df = web.DataReader(ticker, 'yahoo', start, end)\n",
    "            df.reset_index(inplace=True)\n",
    "            df.set_index(\"Date\", inplace=True)\n",
    "            #df = df.drop(\"Symbol\", axis=1)\n",
    "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "\n",
    "\n",
    "#get_data_from_yahoo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_data():\n",
    "    with open(\"sp500tickers.pickle\",\"rb\") as f:\n",
    "        tickers=pickle.load(f)\n",
    "    \n",
    "    main_df=pd.DataFrame()\n",
    "    \n",
    "    for count,ticker in enumerate(tickers):\n",
    "        df=pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        df.set_index('Date',inplace=True)\n",
    "        \n",
    "        df.rename(columns={'Adj Close':ticker},inplace=True)\n",
    "        df.drop(['Open','High','Low','Close','Volume'],1,inplace=True)\n",
    "        \n",
    "        if main_df.empty:\n",
    "            main_df=df\n",
    "        else:\n",
    "            main_df=main_df.join(df,how='outer')\n",
    "        \n",
    "        if count%10==0:\n",
    "            print(count)\n",
    "            \n",
    "    main_df.to_csv(\"sp500_joined_closes.csv\")  \n",
    "#compile_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data():\n",
    "    df=pd.read_csv('sp500_joined_closes.csv')\n",
    "    #df['AAPL'].plot\n",
    "    #plt.show()\n",
    "    df_corr=df.corr()\n",
    "    print(df_corr.head())\n",
    "    \n",
    "    data = df_corr.values\n",
    "    fig=plt.figure()\n",
    "    \n",
    "    ax= fig.add_subplot(1,1,1)\n",
    "    \n",
    "    heatmap=ax.pcolor(data,cmap=plt.cm.RdYlGn)\n",
    "    fig.colorbar(heatmap)\n",
    "    ax.set_xticks(np.arange(data.shape[0]+0.5,minor=False))\n",
    "    ax.set_yticks(np.arange(data.shape[1]+0.5,minor=False))\n",
    "    ax.invert_yaxis()\n",
    "    ax.axis.tick_top()\n",
    "    \n",
    "    column_labels=df_corr.columns\n",
    "    row_labels=df_corr.index\n",
    "    \n",
    "    ax.set_xticklabels(column_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "    \n",
    "    plt.xticks(rotation=90)\n",
    "    heatmap.set_clim(-1,1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#visualize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data spread: Counter({'1': 1008, '-1': 953, '0': 737})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarad\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.35555555555555557\n",
      "Predicted spread: Counter({-1: 323, 1: 236, 0: 116})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35555555555555557"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm_days=7\n",
    "def process_data_for_labels(ticker):\n",
    "    hm_days=7\n",
    "    df=pd.read_csv('sp500_joined_closes.csv',index_col=0)\n",
    "    tickers=df.columns.values.tolist()\n",
    "    \n",
    "    df.fillna(0,inplace=True)\n",
    "    \n",
    "    for i in range(1,hm_days+1):\n",
    "        df['{}_{}d'.format(ticker,i)]= (df[ticker].shift(-i)-df[ticker] )/df[ticker]*100\n",
    "    \n",
    "    df.fillna(0,inplace=True)\n",
    "    return tickers,df\n",
    "\n",
    "def buy_sell_hold(*args):\n",
    "    requirement=.5\n",
    "    cols=[c for c in args]\n",
    "    for col in cols:\n",
    "        if col>requirement:\n",
    "            return 1\n",
    "        if col<-requirement:\n",
    "            return -1\n",
    "        return 0\n",
    "\n",
    "def extract_featuresets(ticker):\n",
    "    tickers,df=process_data_for_labels(ticker)\n",
    "    \n",
    "    df['{}_target'.format(ticker)]=list(map(buy_sell_hold,\n",
    "                                           *[df['{}_{}d'.format(ticker,i)]for i in range(1,hm_days+1)]))\n",
    "    vals=df['{}_target'.format(ticker)].values.tolist()\n",
    "    str_vals=[str(i) for i in vals]\n",
    "    print('Data spread:', Counter(str_vals))\n",
    "    \n",
    "    df.fillna(0,inplace=True)\n",
    "    \n",
    "    df=df.replace([np.inf,-np.inf],np.nan)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    df_vals=df[[ticker for ticker in tickers]].pct_change()\n",
    "    df_vals=df_vals.replace([np.inf,-np.inf],0)\n",
    "    df_vals.fillna(0,inplace=True)\n",
    "    \n",
    "    X=df_vals.values\n",
    "    y=df['{}_target'.format(ticker)].values\n",
    "    \n",
    "    return X,y,df\n",
    "#extract_featuresets('MMM')\n",
    "\n",
    "def do_ml(ticker):\n",
    "    X,y,df=extract_featuresets(ticker)\n",
    "    \n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)\n",
    "   \n",
    "    clf=VotingClassifier([('lsvc',svm.LinearSVC()),\n",
    "                         ('knn',neighbors.KNeighborsClassifier()),\n",
    "                        ('rfor',RandomForestClassifier())])\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    \n",
    "    confidence=clf.score(X_test,y_test)\n",
    "    \n",
    "    print('Accuracy',confidence)\n",
    "    \n",
    "    predictions=clf.predict(X_test)\n",
    "    \n",
    "    print(\"Predicted spread:\",Counter(predictions))\n",
    "    \n",
    "    return confidence\n",
    " \n",
    "    \n",
    "do_ml('BAC')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
